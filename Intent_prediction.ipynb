{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_df = pd.DataFrame(columns=['text','Intent'])\n",
    "filenames = list()\n",
    "intervention_subgraphs = list()\n",
    "for directory, subdirectories, files in os.walk('C:/Users/Tamir/Desktop/HSE_Project/excel_files/'):\n",
    "    for file in files:\n",
    "        filenames.append(os.path.join(directory,file))\n",
    "for filename in filenames:\n",
    "    if (filename[len(filename) - 22] == '~'):\n",
    "        continue\n",
    "    filename = filename.replace(\" \", \" \")\n",
    "    post_df = pd.read_excel(filename)\n",
    "    \n",
    "        #fix to add columns if they are not in the xlsx file\n",
    "    if 'attachments' not in post_df.columns:\n",
    "        post_df['attachments'] = ''\n",
    "    if 'reply_to_comment' not in post_df.columns:\n",
    "        post_df['reply_to_comment'] = 0\n",
    "    if 'reply_to_user' not in post_df.columns:\n",
    "        post_df['reply_to_user'] = 0\n",
    "        \n",
    "    flex_df = post_df.drop(columns=['attachments','date','from_id','id','reply_to_comment','reply_to_user','Content','Intervention'])\n",
    "    data_df = data_df.append(flex_df,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "def clean_text(text, remove_stopwords=True):\n",
    "    \"\"\"\n",
    "    Removes stop words from the given text\n",
    "    :param text: string with the text\n",
    "    :param remove_stopwords: flag to enable removal of stop words\n",
    "    :return: set of tokens without any stop words\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words('russian'))\n",
    "        tokens = [w for w in tokens if w not in stops]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "delete_index = list()\n",
    "\n",
    "for index,row in data_df.iterrows():\n",
    "    if ( not (pd.isnull(data_df['text'].loc[index]) or pd.isnull(data_df['Intent'].loc[index]))   ):\n",
    "        \n",
    "        data_df['text'].loc[index] = clean_text(data_df['text'].loc[index])\n",
    "    else:\n",
    "        delete_index.append(index)\n",
    "\n",
    "data_df = data_df.drop(index = delete_index)\n",
    "data_df = data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "documents = [TaggedDocument(data_df['text'].loc[i], data_df['Intent'].loc[i]) for i in range(len(data_df))]\n",
    "model = Doc2Vec(documents,dm=1, vector_size=5, window=4, min_count=1,epochs=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\Anaconda\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('смогут', 0.9990633130073547),\n",
       " ('хотя', 0.9984726905822754),\n",
       " ('вами', 0.9982699751853943),\n",
       " ('х', 0.9980146884918213),\n",
       " ('страну', 0.9973703622817993),\n",
       " ('войны', 0.9965711236000061),\n",
       " ('id370722155', 0.9963447451591492),\n",
       " ('школе', 0.9955522418022156),\n",
       " ('украину', 0.9950838088989258),\n",
       " ('е', 0.9941287040710449)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('путин')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
